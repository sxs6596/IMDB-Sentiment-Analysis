{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG3IwMUKW_eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcefd93-b1d6-4a38-8354-b442b06e6309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.19.4 safetensors-0.4.0 tokenizers-0.15.0 transformers-4.35.2\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras # keras is a high level API for tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "import seaborn as sns # seaborn is a visualization library based on matplotlib\n",
        "sns.set_style(\"darkgrid\") # set the style of the axes\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split # split data into training and testing set\n",
        "import re, string, nltk\n",
        "from nltk.corpus import stopwords # stopwords are the words that do not contribute to the deeper meaning of the phrase\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier # decision tree classifier\n",
        "from keras.models import Sequential # sequential model\n",
        "from keras.layers import Dense, LSTM, Bidirectional, Dropout # dropout to tackle overfitting\n",
        "from keras.layers import Embedding, Flatten, Dense # embedding layer to create word vectors\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # tfidf vectorizer to convert text into vectors\n",
        "import warnings # to ignore any warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import nltk # natural language toolkit\n",
        "nltk.download('punkt') # punkt is a pre-trained model that helps you tokenize words and sentences\n",
        "!pip install transformers # transformers is a library of state-of-the-art pretrained models for Natural Language Processing (NLP)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Reading the Data '''\n",
        "\n",
        "# reading the csv file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IMDB.csv\")\n",
        "df.head(5) # display first 5 rows of the dataset\n",
        "df.shape # shape of the dataset\n",
        "df = df[[\"review\",\"sentiment\"]] # selecting only review and sentiment columns\n",
        "# shape of data\n",
        "print(f\"Data consists of {df.shape[0]} rows and {df.shape[1]} columns.\")\n"
      ],
      "metadata": {
        "id": "eLGAHVj1XKQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f56db1-9d82-4596-e7c0-30ef6cba870b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data consists of 50000 rows and 2 columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' PreProcessing '''\n",
        "\n",
        "# checking for null values\n",
        "df.isna().sum()\n",
        "# dropping null values\n",
        "df = df.dropna()\n",
        "# checking for null values\n",
        "df1 = df\n",
        "df1.shape\n",
        "\n",
        "def clean_text(df, field):\n",
        "    df[field] = df[field].str.replace(r\"@\",\" at \") # replacing @ with at\n",
        "    df[field] = df[field].str.replace(\"#[^a-zA-Z0-9_]+\",\" \") # replacing #word with word\n",
        "    df[field] = df[field].str.replace(r\"[^a-zA-Z(),\\\"'\\n_]\",\" \") # replacing all characters except alphabets, commas, quotations, newlines and underscores\n",
        "    df[field] = df[field].str.replace(r\"http\\S+\",\"\") # replacing urls with space\n",
        "    df[field] = df[field].str.lower() # converting text to lowercase\n",
        "    return df\n",
        "\n",
        "clean_text(df1,\"review\")\n",
        "\n",
        "\n",
        "\n",
        "# function to lemmatize text\n",
        "def lemmatize(word):\n",
        "    if word.endswith('s'): # removing plural words\n",
        "        if word.endswith('ss'):\n",
        "            return word\n",
        "        return word[:-1]\n",
        "    elif word.endswith('ed'): # removing past tense words\n",
        "        if len(word) > 3 and word[-3] == word[-4]:\n",
        "            return word[:-3]\n",
        "        return word[:-2]\n",
        "    elif word.endswith('ing'):# removing continuous tense words\n",
        "        if len(word) > 4 and word[-4] == word[-5]:\n",
        "            return word[:-4]\n",
        "        return word[:-3]\n",
        "    else:\n",
        "        return word # returning the word as it is\n",
        "\n",
        "# function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text) # replacing won't with will not\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text) # replacing can't with can not\n",
        "    text = re.sub('[^a-zA-Z0-9]',' ',text) # replacing all characters except alphabets and numbers with space\n",
        "    text = [lemmatize(word) for word in text.split()] # lemmatizing words\n",
        "    stop_words = set(['a', 'an', 'the', 'and', 'or', 'but', 'if', 'because', 'as', 'of', 'at', 'by', 'for', 'with', 'about', 'into', 'through', 'during', 'to']) # defining stopwords\n",
        "    text = ' '.join(text) # joining the words\n",
        "    return text # returning the text\n",
        "\n",
        "df1[\"clean_review\"] = df1[\"review\"].apply(preprocess_text) # applying preprocess_text function to review column\n",
        "\n",
        "df1.head()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cl8T_sscXL62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "107c202c-908d-4fc5-839b-3e6904efb646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  one of the other reviewers has mentioned that ...  positive   \n",
              "1  a wonderful little production   br    br   the...  positive   \n",
              "2  i thought this was a wonderful way to spend ti...  positive   \n",
              "3  basically there's a family where a little boy ...  negative   \n",
              "4  petter mattei's \"love in the time of money\" is...  positive   \n",
              "\n",
              "                                        clean_review  \n",
              "0  one of the other reviewer ha mention that afte...  \n",
              "1  a wonderful little production br br the film t...  \n",
              "2  i thought thi wa a wonderful way to spend time...  \n",
              "3  basically there  a family where a little boy j...  \n",
              "4  petter mattei  love in the time of money i a v...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1f1cebb-45a1-4e6e-bd75-6462ccd17d93\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one of the other reviewer ha mention that afte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production   br    br   the...</td>\n",
              "      <td>positive</td>\n",
              "      <td>a wonderful little production br br the film t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>i thought thi wa a wonderful way to spend time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically there  a family where a little boy j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei  love in the time of money i a v...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1f1cebb-45a1-4e6e-bd75-6462ccd17d93')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1f1cebb-45a1-4e6e-bd75-6462ccd17d93 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1f1cebb-45a1-4e6e-bd75-6462ccd17d93');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c582c7f-b022-4099-a2d3-92b74c49e16d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c582c7f-b022-4099-a2d3-92b74c49e16d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c582c7f-b022-4099-a2d3-92b74c49e16d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Train Test Split '''\n",
        "\n",
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(df[\"clean_review\"]),np.array(df[\"sentiment\"]), test_size=0.25,random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "''' TF-IDF Vectorization '''\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf2 = TfidfVectorizer(use_idf=True, tokenizer=word_tokenize)\n",
        "# transforming training and testing set to vectors\n",
        "X_train_tf2 = tfidf2.fit_transform(X_train)\n",
        "X_test_tf2 = tfidf2.transform(X_test)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df[\"clean_review\"]\n",
        "y = df.sentiment\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "display(X_train.shape)\n",
        "display(X_test.shape)\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "# using tokenizer to transform text messages into training and testing set\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=64)\n",
        "X_test_seq_padded = pad_sequences(X_test_seq, maxlen=64)\n",
        "X_train_seq_padded[0]\n"
      ],
      "metadata": {
        "id": "LgFJvuJpXTBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "3602aae0-4306-4648-e424-532627651a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37500,)\n",
            "(12500,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(37500,)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(12500,)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  622,   202,   230,   512,    38,  1075,     6,   277,    60,\n",
              "         152,     8,     8,     6,    21,  1139,     3,   122,  1017,\n",
              "          54,    54,    16,   393,     6,    63,    43,   243,  1094,\n",
              "        4604,     7,   164,    22,    35,  2876,     2,     7,     3,\n",
              "           3,   590,    22,   311,    10,    12,  4799,     7,   109,\n",
              "         887,     6,    63,  1279,  4003,  1777,     2,     1,  2849,\n",
              "          56,   394,  2644,     3,   393,     1,  5948,    13, 23742,\n",
              "         200], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid CNN-RNN model.\n",
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import time\n",
        "\n",
        "st_time  = time.time()\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Amazon_review.csv')\n",
        "reviews = df['review'].values\n",
        "labels = df['sentiment'].values\n",
        "# preprocessing according to the model architecture\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=100)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# CNN architecture\n",
        "input_cnn = Input(shape=(100,)) # input layer\n",
        "embedding_cnn = Embedding(input_dim=5000, output_dim=64)(input_cnn) # embedding layer\n",
        "conv1d_cnn = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding_cnn) # convolutional layer\n",
        "max_pool_cnn = MaxPooling1D(pool_size=2)(conv1d_cnn) # max pooling layer\n",
        "flatten_cnn = tf.keras.layers.Flatten()(max_pool_cnn) # flatten layer\n",
        "dense_cnn = Dense(32, activation='relu')(flatten_cnn) # dense layer\n",
        "\n",
        "# RNN architecture\n",
        "input_rnn = Input(shape=(100,)) # input layer\n",
        "embedding_rnn = Embedding(input_dim=5000, output_dim=64)(input_rnn) # embedding layer\n",
        "lstm_rnn = Bidirectional(LSTM(64, return_sequences=True))(embedding_rnn) # lstm layer\n",
        "lstm_rnn = Bidirectional(LSTM(32))(lstm_rnn) # lstm layer\n",
        "dense_rnn = Dense(32, activation='relu')(lstm_rnn) # dense layer\n",
        "\n",
        "# Merge CNN and RNN outputs\n",
        "merged = tf.keras.layers.concatenate([dense_cnn, dense_rnn], axis=-1)\n",
        "output = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=[input_cnn, input_rnn], outputs=output)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Set up early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "# Train model\n",
        "model.fit([X_train, X_train], y_train, validation_data=([X_test, X_test], y_test), epochs=20, batch_size=64, callbacks=[early_stop])\n",
        "\n",
        "\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/sentiment_model_Hybrid.h5')\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate([X_test, X_test], y_test, verbose=0)\n",
        "print('Test accuracy:', accuracy)\n",
        "\n",
        "en_time = time.time()\n",
        "\n",
        "t_time = en_time - st_time\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(f'total time taken for running hybrid model CNN+ RNN is : {t_time}')"
      ],
      "metadata": {
        "id": "1hbcKSZFXXhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987e72b8-c12d-491e-c161-6e2fd1af64aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1260/1260 [==============================] - 115s 78ms/step - loss: 0.3518 - accuracy: 0.8434 - val_loss: 0.2926 - val_accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "1260/1260 [==============================] - 37s 29ms/step - loss: 0.2372 - accuracy: 0.9039 - val_loss: 0.2723 - val_accuracy: 0.8874\n",
            "Epoch 3/20\n",
            "1260/1260 [==============================] - 34s 27ms/step - loss: 0.1486 - accuracy: 0.9435 - val_loss: 0.3212 - val_accuracy: 0.8773\n",
            "Epoch 4/20\n",
            "1260/1260 [==============================] - 32s 25ms/step - loss: 0.0680 - accuracy: 0.9765 - val_loss: 0.4544 - val_accuracy: 0.8662\n",
            "Epoch 5/20\n",
            "1260/1260 [==============================] - 31s 25ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.5844 - val_accuracy: 0.8722\n",
            "Epoch 5: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8721725940704346\n",
            "\n",
            "\n",
            "total time taken for running hybrid model CNN+ RNN is : 291.09597086906433\n"
          ]
        }
      ]
    }
  ]
}